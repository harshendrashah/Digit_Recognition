{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognition_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshendrashah/Digit_Recognition/blob/master/digit_recognition_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "blXir19ewd-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "697f1373-eaea-472c-b66e-af2c7a444e3f"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pNg3ZWpdwz6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.set_image_dim_ordering('th')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFN7BFMXxEFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fix random seed for reproducibility"
      ]
    },
    {
      "metadata": {
        "id": "wwtQJO4xw-o-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otTZMOZux2bP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load data and reshape to be [samples][pixels][width][height]\n"
      ]
    },
    {
      "metadata": {
        "id": "GIL32JSUxUty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRPZmhI4yX7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalize inputs from 0-255 to 0-1"
      ]
    },
    {
      "metadata": {
        "id": "JQ8waZMWyImh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "luOsN5NRyiup",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One hot encode outputs"
      ]
    },
    {
      "metadata": {
        "id": "CS5YXar7ycfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTB-yaGozIbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline Model\n",
        "\n",
        "1.   The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above [pixels][width][height].\n",
        "2. Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
        "3. The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
        "4. Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
        "5. Next a fully connected layer with 128 neurons and rectifier activation function.\n",
        "6. Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
        "\n",
        "\n",
        "The model is trained using logarithmic loss and the ADAM gradient descent algorithm.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8ryTq7p9ymBV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7w2sgTYz4w9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build, test and train the model"
      ]
    },
    {
      "metadata": {
        "id": "4HvzckGxzvNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "c4a48be0-f0ec-4a53-eddd-02eefd72a47c"
      },
      "cell_type": "code",
      "source": [
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.2225 - acc: 0.9366 - val_loss: 0.0793 - val_acc: 0.9749\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.0714 - acc: 0.9785 - val_loss: 0.0459 - val_acc: 0.9843\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0511 - acc: 0.9843 - val_loss: 0.0452 - val_acc: 0.9854\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0392 - acc: 0.9879 - val_loss: 0.0414 - val_acc: 0.9870\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0325 - acc: 0.9895 - val_loss: 0.0352 - val_acc: 0.9883\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0268 - acc: 0.9916 - val_loss: 0.0330 - val_acc: 0.9890\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0222 - acc: 0.9930 - val_loss: 0.0356 - val_acc: 0.9881\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0332 - val_acc: 0.9886\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0329 - val_acc: 0.9892\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0144 - acc: 0.9958 - val_loss: 0.0318 - val_acc: 0.9901\n",
            "CNN Error: 0.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AdYsl_tw4GRH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A Larger Model\n",
        "\n",
        "1.   Convolutional layer with 30 feature maps of size 5×5.\n",
        "2. Pooling layer taking the max over 2*2 patches.\n",
        "3. Convolutional layer with 15 feature maps of size 3×3.\n",
        "4. Pooling layer taking the max over 2*2 patches.\n",
        "5. Dropout layer with a probability of 20%.\n",
        "6. Flatten layer.\n",
        "7. Fully connected layer with 128 neurons and rectifier activation.\n",
        "8. Fully connected layer with 50 neurons and rectifier activation.\n",
        "9. Output layer.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CygwGwto4DpV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def larger_model():\n",
        "\t# create model\n",
        "\tlrg_model = Sequential()\n",
        "\tlrg_model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "\tlrg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tlrg_model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "\tlrg_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tlrg_model.add(Dropout(0.2))\n",
        "\tlrg_model.add(Flatten())\n",
        "\tlrg_model.add(Dense(128, activation='relu'))\n",
        "\tlrg_model.add(Dense(50, activation='relu'))\n",
        "\tlrg_model.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tlrg_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn lrg_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VG00ObU74h4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "83dad76e-ede4-4e34-dff8-96aa703d6eb6"
      },
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "lrg_model = larger_model()\n",
        "# Fit the model\n",
        "lrg_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "# Final evaluation of the model\n",
        "scores = lrg_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.3702 - acc: 0.8878 - val_loss: 0.0921 - val_acc: 0.9700\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1040 - acc: 0.9683 - val_loss: 0.0580 - val_acc: 0.9829\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0750 - acc: 0.9769 - val_loss: 0.0467 - val_acc: 0.9850\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0602 - acc: 0.9815 - val_loss: 0.0397 - val_acc: 0.9864\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0536 - acc: 0.9831 - val_loss: 0.0350 - val_acc: 0.9882\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0484 - acc: 0.9850 - val_loss: 0.0292 - val_acc: 0.9897\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0418 - acc: 0.9865 - val_loss: 0.0306 - val_acc: 0.9895\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0386 - acc: 0.9879 - val_loss: 0.0281 - val_acc: 0.9901\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.0350 - acc: 0.9887 - val_loss: 0.0299 - val_acc: 0.9902\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0311 - acc: 0.9905 - val_loss: 0.0281 - val_acc: 0.9909\n",
            "Large CNN Error: 0.91%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}